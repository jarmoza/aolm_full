{\rtf1\ansi\ansicpg1252\cocoartf2820
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Palatino-Bold;\f1\froman\fcharset0 Palatino-Roman;\f2\froman\fcharset0 Palatino-Italic;
}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f0\b\fs28 \cf0 Why do we consider data quality for literature?
\f1\b0\fs26 \
\
A few opening questions: 
\f2\i What
\f1\i0  is it we are modeling? Is it literature? Or is it the probability of literature?\
\
In other words, what we are modeling and why is worth considering. The underlying epistemology of a researcher and their project matters because that epistemology will inevitably guide our future decisions in the modeling process, if not now at the beginning when we are looking most directly at the data we are modeling then later on during the modeling of it, during assessments of that model, and then during interpretations/analyses brought forth from it. The argument here is that we should be explicit with our epistemological premises when it comes to dealing with data for computational modeling. What we consider to be \'93valid\'94 literature matters a great deal because we are temporarily transforming text loaded with implicit semantic information into a much more flat form for the sake of modeling it as language, as structured data.\
 Let\'92s say we have dirty data, a novel scanned with OCR errors, for instance. Why would we choose to proceed with modeling it in its present condition? With or without cleanup? The answer usually follows that 
\f2\i statistically
\f1\i0  the model is no worse for wear with some dirty data, but the degree of that dirtiness is not necessarily so clear. What would be the degree of dirtiness that data is allowed to be such that a model of it would be considered a success versus a failure? And if that question is not answerable up front then why not ensure the data is as high quality as possible? So one common activity we could engage in is attempting to clean up such OCR errors, but what if those errors exceed visibility and what if there are other errors within the data that we cannot immediately know or address? Perhaps then let\'92s have a well theorized and implemented test/set of tests that can measure the exact kind(s) of data quality we want for a particular dataset.\
Coleman\'92s data quality assessment framework (DQAF) provides a suitable theoretical structure upon which humanists can hang our own measurements. The kinds of data involved in other contexts, scientific or business worlds for example, may not always exists within a humanities/arts context but there are many categories and kinds of data which Coleman\'92s writings address that 
\f2\i do
\f1\i0  overlap with humanities data. In this case, this work is dedicated to applying such measurements of quality to digitized literature.\
\
Notes:\
\
Developing validity dq code\
Downloaded COHA lexicon to use with validity check - for 19
\fs18 \super th
\fs26 \nosupersub  century American English\
Reassess integrity/consistency code}