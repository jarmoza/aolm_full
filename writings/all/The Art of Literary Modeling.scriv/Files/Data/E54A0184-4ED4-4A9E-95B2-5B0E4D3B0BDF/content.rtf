{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\froman\fcharset0 Palatino-Roman;\f1\froman\fcharset0 Palatino-Italic;\f2\fswiss\fcharset0 Helvetica;
\f3\fswiss\fcharset0 Helvetica-Oblique;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red9\green47\blue157;\red255\green255\blue255;
\red24\green25\blue26;\red169\green0\blue3;}
{\*\expandedcolortbl;;\csgray\c0;\cssrgb\c2353\c27059\c67843;\cssrgb\c100000\c100000\c100000;
\cssrgb\c12549\c12941\c13333;\cssrgb\c72941\c0\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0

\f0\fs32 \cf2 Model quality\
\
Two different directions/considerations for 
\f1\i model selection
\f0\i0 :\
1) Inference\
2) Prediction\
\
{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Model_selection"}}{\fldrslt https://en.wikipedia.org/wiki/Model_selection}}\
\
List of 
\f1\i information criteria metrics:\
{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Model_selection#Criteria"}}{\fldrslt 
\f0\i0 https://en.wikipedia.org/wiki/Model_selection#Criteria}}
\f0\i0 \
\
For example \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa28\partightenfactor0
\ls1\ilvl0
\f2\fs28 \cf3 \cb4 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Akaike_information_criterion"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Akaike information criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(AIC), a measure of the goodness fit of an estimated statistical model\cb1 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Bayes_factor"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Bayes factor}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Bayesian_information_criterion"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Bayesian information criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(BIC), also known as the Schwarz information criterion, a statistical criterion for model selection\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa28\partightenfactor0
\ls1\ilvl0\cf5 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 Bridge criterion (BC), a statistical criterion that can attain the better performance of AIC and BIC despite the appropriateness of model specification.{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Model_selection#cite_note-3"}}{\fldrslt 
\fs22\fsmilli11200 \cf3 \super \strokec3 [3]}}\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa28\partightenfactor0
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Cross-validation_(statistics)"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Cross-validation}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Deviance_information_criterion"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Deviance information criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(DIC), another Bayesian oriented model selection criterion\cb1 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/False_discovery_rate"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 False discovery rate}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Focused_information_criterion"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Focused information criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(FIC), a selection criterion sorting statistical models by their effectiveness for a given focus parameter\cb1 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Hannan%E2%80%93Quinn_information_criterion"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Hannan\'96Quinn information criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 , an alternative to the Akaike and Bayesian criteria\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa28\partightenfactor0
\ls1\ilvl0\cf6 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/w/index.php?title=Kashyap_information_criterion&action=edit&redlink=1"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec6 Kashyap information criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(KIC) is a powerful alternative to AIC and BIC, because KIC uses Fisher information matrix\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa28\partightenfactor0
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Likelihood-ratio_test"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Likelihood-ratio test}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Mallows%27s_Cp"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Mallows's\'a0
\f3\i C
\fs22\fsmilli11200 \sub p}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Minimum_description_length"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Minimum description length}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Minimum_message_length"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Minimum message length}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(MML)\cb1 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/PRESS_statistic"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 PRESS statistic}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 , also known as the PRESS criterion\cb1 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Structural_risk_minimization"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Structural risk minimization}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Stepwise_regression"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Stepwise regression}}\cf5 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \
\ls1\ilvl0\cf3 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Watanabe%E2%80%93Akaike_information_criterion"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Watanabe\'96Akaike information criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(WAIC), also called the widely applicable information criterion\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\sa28\partightenfactor0
\ls1\ilvl0\cf6 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/w/index.php?title=Extended_Bayesian_Information_Criterion&action=edit&redlink=1"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec6 Extended Bayesian Information Criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(EBIC) is an extension of ordinary\'a0{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Bayesian_information_criterion"}}{\fldrslt \cf3 \strokec3 Bayesian information criterion}}\'a0(BIC) for models with high parameter spaces.\cb1 \
\ls1\ilvl0\cf6 \cb4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/w/index.php?title=Extended_Fisher_Information_Criterion&action=edit&redlink=1"}}{\fldrslt \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec6 Extended Fisher Information Criterion}}\cf5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 \'a0(EFIC) is a model selection criterion for linear regression models.\cb1 \
}