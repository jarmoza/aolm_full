{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Palatino-Roman;\f2\froman\fcharset0 Palatino-Italic;
\f3\froman\fcharset0 Palatino-Bold;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid1\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\pard\tx220\tx720\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\li720\fi-720\sl264\slmult1\pardirnatural\partightenfactor0
\ls1\ilvl0
\f0\fs24 \cf0 <$Scr_Ps::0>
\f1 \
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0
\cf2 \
	In fits and starts over the course of his life, Mark Twain attempted to write his autobiography. Toward the end, he dictated much of it to a stenographer. He also came to a peculiar agreement with his publisher and estate in which the work would not be published until 100 years after his death. He reasoned that this would grant him freedom to talk openly about contemporary people and subjects. By the time that anniversary came, the Mark Twain Project at University of California, Berkeley had been preparing the autobiography for years for its eventual publication. As a celebrated American author, it was met with commercial success. However, much to the initial confusion of readers, the entire autobiography would not be published fully until five years later, a volume meted out every two years. The final product was roughly 2,300 pages long. In effect, it was a book popularly bought but not as widely read.\

\f0 <!$Scr_Ps::0>
\f1 \
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0
\cf0 	My dissertation, \'91The Art of Literary Modeling\'92, describes and demonstrates new scholarly activities that provide context-sensitive, evidentiary bases for making interpretive claims from computational models of literature. Its first chapter answers the question, "What does it mean to read literature as data?" That chapter's discussion of "literary" data quality looks to Emily Dickinson's poetry and its complex publication history. My proposed project for the digital humanities summer graduate student fellowship is the programming, modeling experiments, and draft prose for a followup chapter on new means of qualitative and quantitative assessment of model quality for humanities researchers and application of those methods towards uncovering new insights about Twain\'92s sizable autobiography. The digital version of this material, in TEI form, has been supplied to me via the Mark Twain Project Online at University of California. \cf2 \
	\
	Approaching an unwieldy work for reading and interpretation is not a new problem for the humanities, and certainly not for the digital humanities. One might look to previous scholarship, lightly read the whole work while concentrating on a few sections, or, via computation, attempt to represent the work(s) with a model that can describe the entirety of the collection/object while giving insight on mathematically notable sections. For the computational approach there are a few significant decision points. There is the choice of models, sometimes driven by state of the field or by state of the art. And then there is the type of model analysis. How do we comprehend the model and how do we account for how well it represents the underlying textual data? These questions of model selection and estimation of quality are well-theorized in the field of statistics. The question of which model might be most appropriate to understand or discover new insights about Twain\'92s autobiography and works like it, is not though. \
\cf0 \
	That first chapter of my dissertation adapts a series of data quality metrics from information science scholar and career practitioner, Laura Sebastian Coleman, that are typically employed in environments where data sets are dynamic and have external concerns \'96 legal, technical, financial, and otherwise. Newly derived metrics from Coleman\'92s examples concerning the textual consistency and lexical and thematic qualities across Dickinson's multiple, posthumous publications are brought about by analyzing and modeling those publications, ultimately filling out an overall quality assessment of those digital works. When taken into account alongside historical and bibliographic knowledge of the books, this produces a new, amalgam poetry collection from which to conduct future readings, modeling, and analysis.\
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0
\cf2 \
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0

\f0 \cf0 <$Scr_Ps::0>
\f1 	Moving forward from that sensibility for data quality as foundation for modeling literature, this project attempts to answer the followup question: "What does it mean to model literature as data?" Whereas the previous work adapted data quality concepts from information science, this one looks to standards for model selection and quality analysis from statistics known as "information criterion." For instance, a set of information criteria measurements based on and related to one initially developed by Japanese statistician Hirotugu Akaike in the early 1970s, can provide a sense of the relative quality of models by reflecting the amount of information loss between a model and the original data set. While a mathematical description of data generation \'96 in the case of literature, authorship \'96 remains out of reach, Akaike\'92s information criterion measure (and other criteria produced by successive statisticians) allows us to at least understand the difference between the statistical distributions of a work\'92s words (i.e. their likelihood of being used together) according to various kinds of modeling techniques such as frequency analysis, topic models, regression analyses, matrix factorization methods, etc. This comparison made by information criteria presents a new qualitative decision point for the use of literary studies.\cf2 \
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0

\f0 <!$Scr_Ps::0>
\f1 \
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0

\f0 \cf0 <$Scr_Ps::0>
\f1 	Of course, in the case of humanities scholars the quantitative outputs of such measurement can provide a befuddling endpoint. What to do with these numbers? The process of adaptation of such a measurement requires the incorporation of qualitative assessment of sections of a work as deemed notable (or perhaps very unnotable, e.g. hapax legomena) according to the various models being compared. Scholarly knowledge of Twain\'92s life and writings would be posed against the highlights of Twain\'92s autiobiography suggested by high quality models of it. Such comparisons are essentially close readings supported by 
\f2\i qualified
\f1\i0  computation modeling and by the epistemological concerns of more traditional humanities approaches to textual scholarship. These readings/measures of model quality can be also thought of as a new form of annotated knowledge for readers and scholars of Twain\'92s autobiography. As such, they are also generalizable examples of how to engage in a thoughtful discourse between reading and the modeling of literature as data.\
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0

\f0 \cf2 <!$Scr_Ps::0>
\f1 \

\f0 <$Scr_Ps::0>
\f1 \
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0

\f3\b \cf0 \
\pard\tx560\tx1120\tx1800\tx2160\tx2880\tx3600\tx4320\sl264\slmult1\pardirnatural\partightenfactor0

\f0\b0 \cf0 <!$Scr_Ps::0>}