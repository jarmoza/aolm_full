{\rtf1\ansi\ansicpg1252\cocoartf2821
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\deftab720
\pard\pardeftab720\sl640\sa213\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
Traditionally, the differences between the humanities and sciences have been seen through the lens of the character of the knowledge they produce. This was put to pen by C.P. Snow in his famous \'93The Two Cultures\'94 where the former appears to rely on and produce qualitative judgments while the latter relies on and produces quantitative ones. But these have increasingly been seen as false distinctions \'96 to a point \'96 humanistic knowledge has also increasingly been devalued in the public sphere as its cultural utility is made distant from its economic value. It is still within human judgment to distinguish between qualitative and quantitative knowledge even if the difference just seems to be the lack of fixed meanings of words being used as qualitative characterization in the mind of the beholder and across a quantifiable boundary (i.e. something that\'92s more in degree characteristic X than it is characteristic Y).\
The point here is that qualitative judgments/the scales imputed by qualitative judgment can be reasonably applied and mixed with quantitative measurements if but because the distinction between the two seem to be more a matter of the scale of degree of assumptions being done in the measurement itself. Also, to be considered is how a subject matter expert\'92s expertise may lessen the degree of inaccuracy of a more plainly qualitative measurement and in fact impute a more objective consideration for the measurement.\
With that in mind, we can also question the \'93objectivity\'94 of quantitative measurement in that there are always a series of subjective interventions that must be made in order to make that quantitative measurement possible. Consider, for instance what it would mean to merely count words in a text, or to count unique words. Well, what is a word? Each observation made by the computing instrument must decide what a word boundary is and must confront the messiness of human language. Unsurprisingly, the researchers of well-known texts frequently produce difference word counts for them as each of their counting algorithms may have differences in them affected by their own experience and their knowledge of the language context of the text in question. Beyond that, even generalized and reused word counting algorithms still \'93suffer\'94 from their own set of subjective interventions, and it would not matter if an LLM was doing the counting as their own bases for counting words are still produced by humans. Continued use of the LLM counting algorithm merely normalizes one subjective/qualitative form of counting words. So, there is no escape from qualitative assessment or seeming \'93inaccuracy\'94, but merely the degree to which you are aware of the subjectivity/biases of the measurement(s) involved.\
Moving on from there to use measurements to make judgments on the data quality of a natural language text, we can see that both qualitative and quantitative measurement can be mixed as long as the character of each is noted and perhaps the degree or importance of each measurement in the overall data quality measurement is taken into consideration. For instance, it may be suitable to add weights to diminish or enhance the weight of a more subjective measurement ini the overall data quality calculation.\
This action of weighting is also clearly subjective, or, perhaps better-worded, an interpretive move that frequently happens in science and statistics. Though an even weighting (i.e. within a mean calculation) can be used this activity of weighting is clearly an advantageous act within the process of calculating data quality via a customized data quality framework. There are some measurements that will simply take precedence in the mind of the text\'92s subject matter expert and a higher weighitng for that measurement\'92s value is something naturally follows from that expert\'92s expectation. (This, of course, could be a flawed expectation but such is the nature of making judgments.)\
Let\'92s take a look at a study which might have benefited from a data quality assessment. <study here>\
You can see that these calculations and assessments serve two purposes. The first is to produce a quantitative valuation of a dataset for comparison purposes \'96 especially in a world increasingly with a heightened cultural sensibility for quantitative values. This is both a pure and impure purpose you\'92ll note. It seeks to draw attention to the usefulness and veracity of a dataset of natural language text, the underlying content of which is (often) far more meaningful than its reduction to a mere single number. Indeed, such a reduction is anathema to the subject matter expert and to the cultural and artistic value of the material. But none the less we do seek to convey the value of a dataset to those who seek to learn from it \'96 both in quantitative value in existential value. Whether one sensibility is valued over the other is something we as researchers and archivists can merely promote, but it would be folly to ignore either for the concept of \'93utility\'94 exists even in a qualitative or artist\'92s space. Such meta-judgements also betray themselves as indistinguishable when looked at closely enough. (In the contemporary context, there are clear implications towards use-value of a text as object in terms of capital \'96 fiscal or otherwise \'96 and while that cannot be ignored as industry absorbs large swaths of NLP datasets, utility is just as universal from the humanistic perspective in terms of social and cultural capital of a particular author, genres, or texts.)\
\
}