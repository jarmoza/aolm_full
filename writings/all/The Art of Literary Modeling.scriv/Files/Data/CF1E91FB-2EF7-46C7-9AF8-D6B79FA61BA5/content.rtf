{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Palatino-Bold;\f1\froman\fcharset0 Palatino-Roman;\f2\froman\fcharset0 Palatino-Italic;
}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f0\b\fs26 \cf0 On model quality - the purpose behind it
\f1\b0 \
\
Now that we have seen how data quality standards can be established for humanities research practices and projects, the turn to undertaking a better understanding of model quality is only natural. The aim here is take all of our interests, aims, presumptions and carry them through (or defeat them after reflection) the computer-aided interpretations of our objects of interest. And of course, a model is an interpretation under the framework of a methodology. The ideas that led to the use of a model type and the creation of an instance of that model type with our data get compressed and shaped by the limitations of that interpretive, mathematical system. I don\'92t want to shy away from speaking of these interpretations as mathematical systems either. Though an obvious characterization, like the pre-established rules of a poetic form, a mathematical system portrays reality in such a way that conforms to the limits of the system and the parameters that are fed to inform the creation of that system. Thus any extended interpretation from that system faces the same limitations. This phenomenon is directly analogous to 
\f2\i any
\f1\i0  research that has utilized distinct tools to aid/inform its outputs. The ideas radiate outward through comparison.\
How has statistics handled this need to compare the outputs of its methods? Information criterion. That is to ask, \'93What possible criteria can we use to determine whether our information \'96 our model of our data \'96 is lossy in terms of its structure, e.g.  
\f2\i faulty
\f1\i0 ?\'94 And following that question, \'93How does this model\'92s amount of information loss differ from another model\'92s information loss over the same dataset?\'94 It\'92s not so difficult to see the implications of this understanding once model quality comes into play \'96 and comes into play on top of datasets graded by our previously established data quality frameworks.\
Let\'92s imagine an example text analysis/DH project. You have a research question and a potential volume of data that you think can be modeled to answer that question. Let\'92s say you\'92d like to understand how Shakespeare\'92s language in his comedies changed over time. Now the definitive versions of Shakespeare\'92s plays are sometime in contention, but let\'92s say through your data quality framework you were able to establish a qualitative and quantitative metrics that measure each version and then grade them in a DQ framework. The framework suggests a particular version of each play \'96 guided by its scoring. Now what? You could select a set of models you\'92d like to use to attempt to answer your research question \'96 in this case, characterizing Shakespeare\'92s language change in comedies over time. You could select a TF-IDF model, a topic model, a Hidden markov model. And then perform it over the set of versions suggested by the data quality framework. You could even additionally model the versions deemed lesser quality by your DQ framework. Try a variety of values for the respective model parameters as well! And all of this modeling to what end?\
By selecting an information criteria for model quality assessment we now have a means of comparing all of the above models and characterize their comparative information loss and therefore quality. Now, information loss bears a bit explaining still. Information loss from what? Let\'92s speak reductively for a moment and imagine that our dataset represents the real world object it models to 100% accuracy. (Of course, it does not.) Our models above are further simplification of the dataset! So the question becomes how much information from the dataset is lost when the model \'93fits\'94 its dimension reduction on top of the dataset as a means of gaining simpler relationships \'96 and thus understandings \'96 in that dataset.\
\

\f0\b NOTE from the other day: Notion of qualitative check-in points, sampling for verifying data quality with a qualitative metric score}